{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9d4528-4dba-4650-9220-35656c7c080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predikovaný tón: C4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "def predict_tone(file_path, model_path=\"tone_recognition_model.h5\"):\n",
    "    # Načtení natrénovaného modelu\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Parametry (musí odpovídat trénovacímu skriptu)\n",
    "    SAMPLE_RATE = 22050\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    # Načtení a předzpracování audio souboru\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=N_FFT, \n",
    "                                              hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Přizpůsobení tvaru pro model\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)  # Přidání kanálu\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, IMG_SIZE).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)    # Přidání batch dimenze\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    \n",
    "    # Převedení labelu na název tónu\n",
    "    label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\"}\n",
    "    return label_to_tone[predicted_label]\n",
    "\n",
    "# Příklad použití\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"testing/c4_testing/testing_2.wav\"  # Zde zadejte cestu k vašemu .wav souboru\n",
    "    predicted_tone = predict_tone(file_path)\n",
    "    print(f\"Predikovaný tón: {predicted_tone}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f547bf25-0c54-4d0e-9511-3256f4c58d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n",
      "Detailní jistoty:\n",
      "C4: 100.00%\n",
      "D4: 0.00%\n",
      "E4: 0.00%\n",
      "F4: 0.01%\n",
      "G4: 0.00%\n",
      "A4: 0.00%\n",
      "B4: 0.00%\n",
      "Predikovaný tón: C4 | Jistota: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "def predict_tone(file_path, model_path=\"tone_recognition_multi_label.h5\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Parametry\n",
    "    SAMPLE_RATE = 22050\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    # Načtení a zpracování audia\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=N_FFT,\n",
    "                                              hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Příprava vstupu pro model\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, IMG_SIZE).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    \n",
    "    # Predikce s detaily jistoty\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0]) * 100  # Procentuální jistota\n",
    "    \n",
    "    label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "    print(\"Detailní jistoty:\")\n",
    "    for tone, conf in zip([\"C4\", \"D4\", \"E4\",\"F4\", \"G4\", \"A4\", \"B4\"], predictions[0]):\n",
    "        print(f\"{tone}: {conf*100:.2f}%\")\n",
    "    return label_to_tone[predicted_label], confidence\n",
    "\n",
    "# Příklad použití\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"nwm/temp_edit_2.wav\"\n",
    "    predicted_tone, confidence = predict_tone(file_path)\n",
    "    print(f\"Predikovaný tón: {predicted_tone} | Jistota: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1df259a-e48d-4243-96be-73a8ecb37487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahrávám 2 vteřin...\n",
      "Uloženo do temp.wav\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Detailní jistoty:\n",
      "C4: 0.03%\n",
      "D4: 0.00%\n",
      "E4: 0.00%\n",
      "F4: 0.01%\n",
      "G4: 0.00%\n",
      "A4: 99.96%\n",
      "B4: 0.00%\n",
      "Predikovaný tón: A4 | Jistota: 99.96%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd  # Pro nahrávání zvuku\n",
    "import soundfile as sf    # Pro uložení nahraného zvuku\n",
    "\n",
    "def predict_tone(file_path, model_path=\"tone_recognition_model.h5\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Parametry\n",
    "    SAMPLE_RATE = 22050\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    # Načtení a zpracování audia\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=N_FFT,\n",
    "                                              hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Příprava vstupu pro model\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, IMG_SIZE).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "\n",
    "    label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "    print(\"Detailní jistoty:\")\n",
    "    for tone, conf in zip([\"C4\", \"D4\", \"E4\",\"F4\", \"G4\", \"A4\", \"B4\"], predictions[0]):\n",
    "        print(f\"{tone}: {conf*100:.2f}%\")\n",
    "    return label_to_tone[predicted_label], confidence\n",
    "\n",
    "def record_audio(duration=1, sample_rate=22050, filename=\"temp.wav\"):\n",
    "    \"\"\"Nahrává zvuk z mikrofonu a uloží do souboru.\"\"\"\n",
    "    print(f\"Nahrávám {duration} vteřin...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Čeká na dokončení nahrávání\n",
    "    sf.write(filename, audio, sample_rate)\n",
    "    print(f\"Uloženo do {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Nahrání zvuku\n",
    "    record_audio(duration=2)  # Nahrává 1 vteřinu\n",
    "    \n",
    "    # Predikce\n",
    "    predicted_tone, confidence = predict_tone(\"temp.wav\")\n",
    "    print(f\"Predikovaný tón: {predicted_tone} | Jistota: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bbe8e58-9f9e-443d-b038-141bd0dc8802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahrávám 3 vteřin...\n",
      "Uloženo do temp.wav\n",
      "Přehrávám audio...\n",
      "Přehrávání dokončeno\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Detailní jistoty:\n",
      "C4: 0.10%\n",
      "D4: 0.00%\n",
      "E4: 0.00%\n",
      "F4: 0.89%\n",
      "G4: 0.00%\n",
      "A4: 30.51%\n",
      "B4: 0.00%\n",
      "Predikovaný tón: A4 | Jistota: 30.51%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd  # Pro nahrávání a přehrávání\n",
    "import soundfile as sf    # Pro práci se soubory\n",
    "\n",
    "def predict_tone(file_path, model_path=\"tone_recognition_multi_label.h5\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Parametry\n",
    "    SAMPLE_RATE = 22050\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    # Načtení a zpracování audia\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=N_FFT,\n",
    "                                              hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Příprava vstupu pro model\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, IMG_SIZE).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "\n",
    "    label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "    print(\"Detailní jistoty:\")\n",
    "    for tone, conf in zip([\"C4\", \"D4\", \"E4\",\"F4\", \"G4\", \"A4\", \"B4\"], predictions[0]):\n",
    "        print(f\"{tone}: {conf*100:.2f}%\")\n",
    "    return label_to_tone[predicted_label], confidence\n",
    "\n",
    "def record_audio(duration=1, sample_rate=22050, filename=\"temp.wav\"):\n",
    "    \"\"\"Nahrává zvuk z mikrofonu a uloží do souboru.\"\"\"\n",
    "    print(f\"Nahrávám {duration} vteřin...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Čeká na dokončení nahrávání\n",
    "    sf.write(filename, audio, sample_rate)\n",
    "    print(f\"Uloženo do {filename}\")\n",
    "    return audio  # Vracíme nahrané audio pro případné přehrání\n",
    "\n",
    "def play_audio(file_path):\n",
    "    \"\"\"Přehrává audio ze souboru.\"\"\"\n",
    "    audio, sr = sf.read(file_path)\n",
    "    print(\"Přehrávám audio...\")\n",
    "    sd.play(audio, sr)\n",
    "    sd.wait()  # Čeká na dokončení přehrávání\n",
    "    print(\"Přehrávání dokončeno\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Nahrání zvuku\n",
    "    record_audio(duration=3)  # Nahrává 1 vteřinu\n",
    "    \n",
    "    # Přehrání pro kontrolu\n",
    "    play_audio(\"temp.wav\")\n",
    "    \n",
    "    # Predikce\n",
    "    predicted_tone, confidence = predict_tone(\"temp.wav\")\n",
    "    print(f\"Predikovaný tón: {predicted_tone} | Jistota: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e65a78d-8054-462b-8798-f2e148e59e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahrávám 3 vteřin...\n",
      "Uloženo do temp.wav (zesílení: 3.0x)\n",
      "Přehrávám audio (zesílení: 2.0x)...\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Detailní jistoty:\n",
      "C4: 0.28%\n",
      "D4: 0.00%\n",
      "E4: 0.00%\n",
      "F4: 3.85%\n",
      "G4: 0.00%\n",
      "A4: 0.97%\n",
      "B4: 0.00%\n",
      "Predikovaný tón: F4 | Jistota: 3.85%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd  # Pro nahrávání a přehrávání\n",
    "import soundfile as sf    # Pro práci se soubory\n",
    "\n",
    "def predict_tone(file_path, model_path=\"tone_recognition_multi_label.h5\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Parametry\n",
    "    SAMPLE_RATE = 22050\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    # Načtení a zpracování audia\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=N_FFT,\n",
    "                                              hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Příprava vstupu pro model\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, IMG_SIZE).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "\n",
    "    label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "    print(\"Detailní jistoty:\")\n",
    "    for tone, conf in zip([\"C4\", \"D4\", \"E4\",\"F4\", \"G4\", \"A4\", \"B4\"], predictions[0]):\n",
    "        print(f\"{tone}: {conf*100:.2f}%\")\n",
    "    return label_to_tone[predicted_label], confidence\n",
    "\n",
    "\n",
    "\n",
    "def adjust_volume(audio, gain=4.0):\n",
    "    \"\"\"Zesílí audio signál a ohlídá clipping.\"\"\"\n",
    "    amplified = audio * gain\n",
    "    \n",
    "    # Oříznutí hodnot mimo rozsah [-1.0, 1.0] pro prevenci zkreslení\n",
    "    amplified = np.clip(amplified, -1.0, 1.0)\n",
    "    return amplified\n",
    "\n",
    "def record_audio(duration=1, sample_rate=22050, filename=\"temp.wav\", gain=2.0):\n",
    "    \"\"\"Nahrává zvuk a automaticky zesílí hlasitost.\"\"\"\n",
    "    print(f\"Nahrávám {duration} vteřin...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()\n",
    "    \n",
    "    # Zesílení a normalizace\n",
    "    audio = adjust_volume(audio, gain)\n",
    "    \n",
    "    sf.write(filename, audio, sample_rate)\n",
    "    print(f\"Uloženo do {filename} (zesílení: {gain}x)\")\n",
    "    return audio\n",
    "\n",
    "def play_audio(file_path, gain=1.0):\n",
    "    \"\"\"Přehrává audio s možností zesílení.\"\"\"\n",
    "    audio, sr = sf.read(file_path)\n",
    "    audio = adjust_volume(audio, gain)  # Zesílení při přehrávání\n",
    "    print(f\"Přehrávám audio (zesílení: {gain}x)...\")\n",
    "    sd.play(audio, sr)\n",
    "    sd.wait()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Nahrání se zesílením 3x\n",
    "    record_audio(duration=3, gain=3.0)\n",
    "    \n",
    "    # Přehrání se zesílením 2x (pro ještě větší hlasitost)\n",
    "    play_audio(\"temp.wav\", gain=2.0)\n",
    "    \n",
    "    # Predikce\n",
    "    predicted_tone, confidence = predict_tone(\"temp.wav\")\n",
    "    print(f\"Predikovaný tón: {predicted_tone} | Jistota: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "172db72c-c6a5-49d6-92d4-0cff4467f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahrávám 3 vteřin...\n",
      "Audio oříznuto na onset v čase 0.07s\n",
      "\n",
      "Přehrávám oříznuté audio...\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "\n",
      "Detailní jistoty:\n",
      "C4: 0.00%\n",
      "D4: 0.00%\n",
      "E4: 0.00%\n",
      "F4: 0.00%\n",
      "G4: 0.00%\n",
      "A4: 99.78%\n",
      "B4: 0.00%\n",
      "\n",
      "Predikovaný tón: A4 | Jistota: 99.78%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "def adjust_volume(audio, gain=2.0):\n",
    "    amplified = audio * gain\n",
    "    return np.clip(amplified, -1.0, 1.0)\n",
    "\n",
    "def record_audio(duration=1, sample_rate=22050, filename=\"temp.wav\", gain=2.0):\n",
    "    print(f\"Nahrávám {duration} vteřin...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()\n",
    "    \n",
    "    # Zesílení a převod na 1D pole\n",
    "    audio = adjust_volume(audio.squeeze(), gain)\n",
    "    \n",
    "    # Detekce onsetů s vašimi parametry\n",
    "    onsets = librosa.onset.onset_detect(\n",
    "        y=audio,\n",
    "        sr=sample_rate,\n",
    "        units='time',\n",
    "        hop_length=512,\n",
    "        pre_max=3,\n",
    "        post_max=3,\n",
    "        pre_avg=3,\n",
    "        post_avg=3,\n",
    "        delta=0.3,\n",
    "        wait=0\n",
    "    )\n",
    "    \n",
    "    # Oříznutí na první onset\n",
    "    if len(onsets) > 0:\n",
    "        start_time = onsets[0]\n",
    "        start_sample = int(start_time * sample_rate)\n",
    "        trimmed_audio = audio[start_sample:]\n",
    "        print(f\"Audio oříznuto na onset v čase {start_time:.2f}s\")\n",
    "    else:\n",
    "        trimmed_audio = audio\n",
    "        print(\"Onset nebyl detekován. Používám celou nahrávku.\")\n",
    "    \n",
    "    # Uložení oříznutého audia\n",
    "    sf.write(filename, trimmed_audio, sample_rate)\n",
    "    return trimmed_audio\n",
    "\n",
    "def predict_tone(file_path, model_path=\"tone_recognition_multi_label.h5\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Načtení a zpracování\n",
    "    signal, sr = librosa.load(file_path, sr=22050)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Příprava vstupu\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "\n",
    "    label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "    print(\"\\nDetailní jistoty:\")\n",
    "    for tone, conf in zip(label_to_tone.values(), predictions[0]):\n",
    "        print(f\"{tone}: {conf*100:.2f}%\")\n",
    "    return label_to_tone[predicted_label], confidence\n",
    "\n",
    "def play_audio(file_path):\n",
    "    audio, sr = sf.read(file_path)\n",
    "    print(\"\\nPřehrávám oříznuté audio...\")\n",
    "    sd.play(audio, sr)\n",
    "    sd.wait()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Nahrání s agresivním zesílením\n",
    "    record_audio(duration=3, gain=3.0)\n",
    "    \n",
    "    # Kontrola a predikce\n",
    "    play_audio(\"temp.wav\")\n",
    "    predicted_tone, confidence = predict_tone(\"temp.wav\")\n",
    "    print(f\"\\nPredikovaný tón: {predicted_tone} | Jistota: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec15feb4-137c-4f3f-aaea-e5ec5a0caf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n",
      "Detekován tón: A4 | Jistota: 91.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 90.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 96.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 94.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 90.3%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 90.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 89.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 95.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.3%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 92.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 35.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 76.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 65.7%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 98.2%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 98.2%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 99.6%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: C4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 95.8%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 48.8%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 48.8%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 51.6%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 96.9%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 96.8%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 62.7%\n",
      "\n",
      "Detekován tón: D4 | Jistota: 62.7%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 77.5%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 77.5%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 83.9%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 85.4%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 89.2%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 89.5%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 91.7%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 28.8%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 6.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 49.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 50.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 54.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 17.3%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 4.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 88.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 80.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 69.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 75.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 68.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 68.0%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 31.1%\n",
      "\n",
      "Detekován tón: F4 | Jistota: 31.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 64.6%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: G4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 32.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 73.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 86.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 90.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 96.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 46.4%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: B4 | Jistota: 49.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 59.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 59.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 95.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 95.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 92.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 79.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 1.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 84.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 94.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 94.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 89.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 89.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 96.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 92.3%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 89.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 92.3%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 91.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 94.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 93.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 92.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.5%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 98.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 83.3%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 46.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 50.3%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 100.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.4%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 99.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 96.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 97.2%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 91.7%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 90.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 92.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 89.6%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 90.9%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 93.1%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 94.0%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 85.8%\n",
      "\n",
      "Detekován tón: A4 | Jistota: 83.4%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(segment) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2048\u001b[39m:  \u001b[38;5;66;03m# Minimální délka pro analýzu\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     is_playing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     predicted_label, confidence \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     tone \u001b[38;5;241m=\u001b[39m label_to_tone[predicted_label]\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetekován tón: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtone\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Jistota: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 40\u001b[0m, in \u001b[0;36mprocess_audio\u001b[1;34m(buffer)\u001b[0m\n\u001b[0;32m     37\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mel_spec_db, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Predikce\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m]), np\u001b[38;5;241m.\u001b[39mmax(predictions[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2620\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2617\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2618\u001b[0m         )\n\u001b[1;32m-> 2620\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:353\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 353\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2325\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2323\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[1;32m-> 2325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[1;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:33\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m---> 33\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, dataset_ops\u001b[38;5;241m.\u001b[39mDatasetSpec):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_ops\u001b[38;5;241m.\u001b[39mget_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    693\u001b[0m )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:335\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    333\u001b[0m num_in_full_batch \u001b[38;5;241m=\u001b[39m num_full_batches \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m    334\u001b[0m first_k_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mslice(indices, [\u001b[38;5;241m0\u001b[39m], [num_in_full_batch])\n\u001b[1;32m--> 335\u001b[0m first_k_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfirst_k_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_full_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m flat_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(first_k_indices)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_batch_size:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:201\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     66\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m   shape_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    203\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8759\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8757\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   8758\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 8759\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8760\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8761\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   8762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:778\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[1;32m--> 778\u001b[0m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[0;32m    782\u001b[0m                            default_type_attr_map, attrs)\n\u001b[0;32m    783\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:531\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[0;32m    529\u001b[0m inferred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 531\u001b[0m   inferred \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;66;03m# When converting a python object such as a list of Dimensions, we\u001b[39;00m\n\u001b[0;32m    535\u001b[0m   \u001b[38;5;66;03m# need a dtype to be specified, thus tensor conversion may throw\u001b[39;00m\n\u001b[0;32m    536\u001b[0m   \u001b[38;5;66;03m# an exception which we will ignore and try again below.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[0;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:286\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_broadcast\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:268\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    266\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    267\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[1;32m--> 268\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m    272\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m    273\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m    275\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   2649\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   2651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 2652\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2657\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2658\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2659\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2660\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2662\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   2663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1160\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1017\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1013\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1014\u001b[0m                                          serialized)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1017\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1019\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0  # Délka bufferu v sekundách\n",
    "ONSET_THRESHOLD = 0.3  # Citlivost detekce začátku tónu\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "# Fronta pro přenos dat mezi streamem a hlavním vláknem\n",
    "audio_queue = Queue()\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Funkce volaná pro každý nový audio blok.\"\"\"\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    \"\"\"Zpracuje audio buffer a vrátí predikovaný tón.\"\"\"\n",
    "    # Generování mel spektrogramu\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=buffer,\n",
    "        sr=SAMPLE_RATE,\n",
    "        n_fft=2048,\n",
    "        hop_length=512,\n",
    "        n_mels=128\n",
    "    )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Příprava pro model\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    \"\"\"Detekuje onset v aktuálním bufferu.\"\"\"\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer,\n",
    "        sr=SAMPLE_RATE,\n",
    "        units='samples',\n",
    "        hop_length=512,\n",
    "        delta=ONSET_THRESHOLD,\n",
    "        pre_max=3,\n",
    "        post_max=3\n",
    "    )\n",
    "\n",
    "# Slovník pro překlad labelů\n",
    "label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "\n",
    "# Spuštění streamu\n",
    "with sd.InputStream(\n",
    "    callback=audio_callback,\n",
    "    channels=1,\n",
    "    samplerate=SAMPLE_RATE,\n",
    "    blocksize=int(SAMPLE_RATE * 0.1)  # 100ms bloky\n",
    "):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\")\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    is_playing = False\n",
    "    \n",
    "    while True:\n",
    "        # Načtení dat z fronty\n",
    "        while not audio_queue.empty():\n",
    "            new_data = audio_queue.get().squeeze()\n",
    "            buffer = np.concatenate([buffer, new_data])\n",
    "        \n",
    "        # Udržujeme buffer o délce BUFFER_DURATION\n",
    "        if len(buffer) > SAMPLE_RATE * BUFFER_DURATION:\n",
    "            buffer = buffer[-int(SAMPLE_RATE * BUFFER_DURATION):]\n",
    "        \n",
    "        # Detekce onsetu\n",
    "        onsets = detect_onset(buffer)\n",
    "        \n",
    "        if len(onsets) > 0 and not is_playing:\n",
    "            # Zpracování od posledního onsetu\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:  # Minimální délka pro analýzu\n",
    "                is_playing = True\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                tone = label_to_tone[predicted_label]\n",
    "                print(f\"\\nDetekován tón: {tone} | Jistota: {confidence*100:.1f}%\")\n",
    "                is_playing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4722baac-badc-4fce-be0c-04741a55eef3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqueue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Queue\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\values.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:205\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:99\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils_exp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_tensor\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m internal\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor.py:2320\u001b[0m\n\u001b[0;32m   2313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;66;03m# ===============================================================================\u001b[39;00m\n\u001b[0;32m   2317\u001b[0m \u001b[38;5;66;03m# RaggedTensorSpec\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m \u001b[38;5;66;03m# ===============================================================================\u001b[39;00m\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;129;43m@tf_export\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRaggedTensorSpec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m-> 2320\u001b[0m \u001b[38;5;129;43m@type_spec_registry\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf.RaggedTensorSpec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mRaggedTensorSpec\u001b[39;49;00m\u001b[43m(\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchableTypeSpec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRaggedTensorSpec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[38;5;250;43m  \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Type specification for a `tf.RaggedTensor`.\"\"\"\u001b[39;49;00m\n\u001b[0;32m   2325\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;18;43m__slots__\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_shape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_ragged_rank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_row_splits_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_flat_values_spec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\type_spec_registry.py:59\u001b[0m, in \u001b[0;36mregister.<locals>.decorator_fn\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has already been registered with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     57\u001b[0m                    (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, _TYPE_SPEC_TO_NAME[\u001b[38;5;28mcls\u001b[39m]))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _NAME_TO_TYPE_SPEC:\n\u001b[1;32m---> 59\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has already been registered for class \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     60\u001b[0m                    (name, _NAME_TO_TYPE_SPEC[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m,\n\u001b[0;32m     61\u001b[0m                     _NAME_TO_TYPE_SPEC[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m     62\u001b[0m _TYPE_SPEC_TO_NAME[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m     63\u001b[0m _NAME_TO_TYPE_SPEC[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = {0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\"}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                tone = label_to_tone[predicted_label]\n",
    "                output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                print(f\"Poslední detekce: {output} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                last_detection_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e296f0-97f1-42db-8863-f78710b2dde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n",
      "Poslední detekce:                       Čekám na tón..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poslední detekce: E6 (0.4%)            | Čas: 22:31:35"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x00000169F99CF560>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\weakref.py\", line 369, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poslední detekce: A4 (2.5%)            | Čas: 22:31:38"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SUPER FUNGUJE!!! NEJLEPŠÍ ZATÍM!\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = label_to_tone = {\n",
    "    0: \"C4\", \n",
    "    1: \"D4\", \n",
    "    2: \"E4\", \n",
    "    3: \"F4\", \n",
    "    4: \"G4\", \n",
    "    5: \"A4\", \n",
    "    6: \"B4\", \n",
    "    7: \"C5\", \n",
    "    8: \"D5\", \n",
    "    9: \"E5\", \n",
    "    10: \"F5\", \n",
    "    11: \"G5\", \n",
    "    12: \"A5\", \n",
    "    13: \"B5\", \n",
    "    14: \"C6\", \n",
    "    15: \"D6\", \n",
    "    16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                tone = label_to_tone[predicted_label]\n",
    "                output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                print(f\"Poslední detekce: {output} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                last_detection_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d72004-5b78-486e-b024-1f00e61e72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Temp\\ipykernel_22824\\3472168640.py\", line 17, in <module>\n",
      "    svm_filter = load('kalimba_filter.joblib')\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 658, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 577, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py\", line 1213, in load\n",
      "    dispatch[key[0]](self)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py\", line 1538, in load_stack_global\n",
      "    self.append(self.find_class(module, name))\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py\", line 1580, in find_class\n",
      "    __import__(module, level=0)\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py\", line 83, in <module>\n",
      "    from .base import clone\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from scipy.sparse import issparse\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\__init__.py\", line 274, in <module>\n",
      "    from ._csr import *\n",
      "  File \"C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m MIN_DELAY \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Načtení modelů\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m svm_filter \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkalimba_filter.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m ocsvm \u001b[38;5;241m=\u001b[39m svm_filter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m scaler \u001b[38;5;241m=\u001b[39m svm_filter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compress, islice\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\__init__.py:274\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix, _array_doc_to_matrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "from joblib import load\n",
    "\n",
    "# Konfigurace\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.5\n",
    "MIN_SEGMENT_LENGTH = 2048\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5\n",
    "\n",
    "# Načtení modelů\n",
    "svm_filter = load('kalimba_filter.joblib')\n",
    "ocsvm = svm_filter['model']\n",
    "scaler = svm_filter['scaler']\n",
    "cnn_model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "label_to_tone = {\n",
    "    0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\",\n",
    "    5: \"A4\", 6: \"B4\", 7: \"C5\", 8: \"D5\", 9: \"E5\",\n",
    "    10: \"F5\", 11: \"G5\", 12: \"A5\", 13: \"B5\", \n",
    "    14: \"C6\", 15: \"D6\", 16: \"E6\"\n",
    "}\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def extract_features(buffer):\n",
    "    if len(buffer) < 512:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Základní kontrola energie signálu\n",
    "        if librosa.feature.rms(y=buffer).mean() < 0.001:\n",
    "            return None\n",
    "            \n",
    "        mfcc = librosa.feature.mfcc(y=buffer, sr=SAMPLE_RATE, n_mfcc=20)\n",
    "        mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "        \n",
    "        # Výpočet chroma s explicitními parametry\n",
    "        chroma = librosa.feature.chroma_stft(\n",
    "            y=buffer, \n",
    "            sr=SAMPLE_RATE,\n",
    "            n_fft=2048,\n",
    "            hop_length=512,\n",
    "            tuning=0.0  # Explicitně zakážeme automatické ladění\n",
    "        )\n",
    "        \n",
    "        sc = np.mean(librosa.feature.spectral_centroid(y=buffer, sr=SAMPLE_RATE))\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(buffer))\n",
    "        \n",
    "        return np.concatenate([mfcc_mean, [sc, zcr, np.mean(chroma)]])\n",
    "    except Exception as e:\n",
    "        print(f\"Feature extraction error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def is_kalimba(buffer, threshold=-0.5):\n",
    "    if len(buffer) < MIN_SEGMENT_LENGTH:\n",
    "        return False\n",
    "    \n",
    "    features = extract_features(buffer)\n",
    "    if features is None or features.shape[0] != 23:  # 20 MFCC + 3 features\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        scaled = scaler.transform([features])\n",
    "        return ocsvm.decision_function(scaled) > threshold\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def process_audio(buffer):\n",
    "    if len(buffer) < MIN_SEGMENT_LENGTH or not is_kalimba(buffer):\n",
    "        return None, 0\n",
    "    \n",
    "    try:\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128\n",
    "        )\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_db = np.expand_dims(np.expand_dims(mel_db, -1), 0)\n",
    "        mel_db = tf.image.resize(mel_db, (128, 128)).numpy()\n",
    "        preds = cnn_model.predict(mel_db, verbose=0)\n",
    "        return np.argmax(preds[0]), np.max(preds[0])\n",
    "    except:\n",
    "        return None, 0\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    try:\n",
    "        return librosa.onset.onset_detect(\n",
    "            y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "            delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "        )\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "with sd.InputStream(\n",
    "    callback=audio_callback,\n",
    "    channels=1,\n",
    "    samplerate=SAMPLE_RATE,\n",
    "    blocksize=int(SAMPLE_RATE * 0.1)\n",
    "):\n",
    "    print(\"=== KALIMBA DETECTOR ===\")\n",
    "    print(\"Hrajte tóny... (Ctrl+C pro ukončení)\\n\")\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        max_length = int(SAMPLE_RATE * BUFFER_DURATION)\n",
    "        buffer = buffer[-max_length:] if len(buffer) > max_length else buffer\n",
    "        \n",
    "        # Hlavní detekce\n",
    "        if len(buffer) >= MIN_SEGMENT_LENGTH:\n",
    "            onsets = detect_onset(buffer)\n",
    "            current_time = time.time()\n",
    "            \n",
    "            if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "                start = max(onsets[-1], 0)\n",
    "                end = start + MIN_SEGMENT_LENGTH\n",
    "                \n",
    "                if end <= len(buffer):\n",
    "                    segment = buffer[start:end]\n",
    "                    label, conf = process_audio(segment)\n",
    "                    \n",
    "                    if label is not None and conf > 0.5:\n",
    "                        tone = label_to_tone.get(label, \"Neznámý\")\n",
    "                        print(f\"{tone} ({conf*100:.1f}%)\".ljust(20) + f\"| {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                        last_detection_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a35d3975-a1aa-476d-a2d3-9050b49ed254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ad7c1-1625-4795-83d4-cf88698655c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = label_to_tone = {\n",
    "    0: \"C4\", \n",
    "    1: \"D4\", \n",
    "    2: \"E4\", \n",
    "    3: \"F4\", \n",
    "    4: \"G4\", \n",
    "    5: \"A4\", \n",
    "    6: \"B4\", \n",
    "    7: \"C5\", \n",
    "    8: \"D5\", \n",
    "    9: \"E5\", \n",
    "    10: \"F5\", \n",
    "    11: \"G5\", \n",
    "    12: \"A5\", \n",
    "    13: \"B5\", \n",
    "    14: \"C6\", \n",
    "    15: \"D6\", \n",
    "    16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                tone = label_to_tone[predicted_label]\n",
    "                output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                print(f\"Poslední detekce: {output} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                last_detection_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad7f000f-d79a-4b49-b395-5c56fa0b73c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n",
      "Poslední detekce: Čekám na tón...       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n",
      "SVM predikce: -1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m buffer \u001b[38;5;241m=\u001b[39m buffer[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(SAMPLE_RATE\u001b[38;5;241m*\u001b[39mBUFFER_DURATION):] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m>\u001b[39m SAMPLE_RATE\u001b[38;5;241m*\u001b[39mBUFFER_DURATION \u001b[38;5;28;01melse\u001b[39;00m buffer\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Detekce onsetů\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m onsets \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_onset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(onsets) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (current_time \u001b[38;5;241m-\u001b[39m last_detection_time) \u001b[38;5;241m>\u001b[39m MIN_DELAY:\n",
      "Cell \u001b[1;32mIn[46], line 49\u001b[0m, in \u001b[0;36mdetect_onset\u001b[1;34m(buffer)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_onset\u001b[39m(buffer):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monset_detect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mONSET_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\onset.py:158\u001b[0m, in \u001b[0;36monset_detect\u001b[1;34m(y, sr, onset_envelope, hop_length, backtrack, energy, units, normalize, sparse, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my or onset_envelope must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m     onset_envelope \u001b[38;5;241m=\u001b[39m \u001b[43monset_strength\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Shift onset envelope up to be non-negative\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# (a common normalization step to make the threshold more consistent)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Normalize onset strength function to [0, 1] range\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Normalization is performed over the trailing axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\onset.py:351\u001b[0m, in \u001b[0;36monset_strength\u001b[1;34m(y, sr, S, lag, max_size, ref, detrend, center, feature, aggregate, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m    348\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate parameter cannot be False when computing full-spectrum onset strength.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m     )\n\u001b[1;32m--> 351\u001b[0m odf_all \u001b[38;5;241m=\u001b[39m \u001b[43monset_strength_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetrend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m odf_all[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\onset.py:581\u001b[0m, in \u001b[0;36monset_strength_multi\u001b[1;34m(y, sr, S, n_fft, hop_length, lag, max_size, ref, detrend, center, feature, aggregate, channels, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;66;03m# First, compute mel spectrogram\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     S \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mfeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# Convert to dBs\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     S \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mpower_to_db(S)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\feature\\spectral.py:2143\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2130\u001b[0m S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[0;32m   2131\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2132\u001b[0m     S\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2139\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2140\u001b[0m )\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m-> 2143\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m \u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...ft,mf->...mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, S, mel_basis, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\filters.py:252\u001b[0m, in \u001b[0;36mmel\u001b[1;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[0;32m    249\u001b[0m     weights \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mnormalize(weights, norm\u001b[38;5;241m=\u001b[39mnorm, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Only check weights if f_mel[0] is positive\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall((mel_f[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m (\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# This means we have an empty channel somewhere\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty filters detected in mel frequency basis. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome channels will produce empty responses. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    260\u001b[0m     )\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:39\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     33\u001b[0m     _complex_to_float\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m     34\u001b[0m         nt\u001b[38;5;241m.\u001b[39mdtype(nt\u001b[38;5;241m.\u001b[39mclongdouble) : nt\u001b[38;5;241m.\u001b[39mdtype(nt\u001b[38;5;241m.\u001b[39mlongdouble),\n\u001b[0;32m     35\u001b[0m     })\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# avoid keyword arguments to speed up parsing, saves about 15%-20% for very\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# small reductions\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "import joblib\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "\n",
    "# Načtení modelů\n",
    "tone_model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "svm_model = joblib.load(\"kalimba_ocsvm.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Labely tónů\n",
    "label_to_tone = {\n",
    "    0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\",\n",
    "    7: \"C5\", 8: \"D5\", 9: \"E5\", 10: \"F5\", 11: \"G5\", 12: \"A5\", 13: \"B5\",\n",
    "    14: \"C6\", 15: \"D6\", 16: \"E6\"\n",
    "}\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "last_detected_tone = \"Čekám na tón...\"  # Uchovává poslední validní tón\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "# Funkce pro extrakci MFCC příznaků pro SVM\n",
    "def extract_svm_features(audio_segment):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_segment, sr=SAMPLE_RATE, n_mfcc=20)\n",
    "    return np.mean(mfccs, axis=1)  # Průměr přes časovou osu\n",
    "\n",
    "# Funkce pro extrakci mel spektrogramu pro CNN model\n",
    "def extract_mel_spectrogram(audio_segment):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio_segment, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    return np.expand_dims(mel_spec_db, axis=0)\n",
    "\n",
    "# Funkce pro detekci onsetů (začátků tónů)\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(f\"Poslední detekce: {last_detected_tone}\".ljust(40), end='\\r')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:  # Zajistíme, že segment má dostatek dat\n",
    "                \n",
    "                # **1) Ověření pomocí One-Class SVM**\n",
    "                svm_features = extract_svm_features(segment)\n",
    "                svm_features_scaled = scaler.transform([svm_features])\n",
    "                svm_prediction = svm_model.predict(svm_features_scaled)\n",
    "\n",
    "                print(f\"SVM predikce: {svm_prediction[0]}\")\n",
    "\n",
    "                if svm_prediction[0] == -1:\n",
    "                    continue  # Pokud zvuk neodpovídá kalimbě, ignorujeme ho\n",
    "                \n",
    "                # **2) Klasifikace konkrétního tónu pomocí CNN**\n",
    "                input_data = extract_mel_spectrogram(segment)\n",
    "                predictions = tone_model.predict(input_data, verbose=0)\n",
    "                \n",
    "                predicted_label = np.argmax(predictions[0])\n",
    "                confidence = np.max(predictions[0])\n",
    "                new_tone = f\"{label_to_tone[predicted_label]} ({confidence*100:.1f}%)\"\n",
    "\n",
    "                if new_tone != last_detected_tone:  # Výpis se změní jen při detekci nového tónu\n",
    "                    last_detected_tone = new_tone\n",
    "                    print(f\"Poslední detekce: {last_detected_tone}\".ljust(40), end='\\r')\n",
    "\n",
    "                last_detection_time = current_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b3ade68-4a66-42cb-9d88-d40763c39cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n",
      "Poslední detekce:                       Čekám na tón...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Cizí zvuk ignorován]        e        | Čas: 01:14:08\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# Krátkodobá informace o cizím zvuku bez přepsání detekce\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [Cizí zvuk ignorován]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m30\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Krátká pauza pro čitelnost\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoslední detekce: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_tone\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m20\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Čas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "import joblib\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5\n",
    "\n",
    "# Načtení modelů\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "svm_model = joblib.load(\"kalimba_ocsvm.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "last_tone = \"Žádná detekce\"  # Uchovává poslední platný tón\n",
    "label_to_tone = {\n",
    "    0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\",\n",
    "    7: \"C5\", 8: \"D5\", 9: \"E5\", 10: \"F5\", 11: \"G5\", 12: \"A5\", 13: \"B5\",\n",
    "    14: \"C6\", 15: \"D6\", 16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "def extract_features(audio_data, sr=22050):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=20)\n",
    "    return np.mean(mfccs, axis=1)\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezení délky bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                # Ověření pomocí SVM\n",
    "                mfcc_features = extract_features(segment, SAMPLE_RATE)\n",
    "                scaled_features = scaler.transform([mfcc_features])\n",
    "                is_kalimba = svm_model.predict(scaled_features)[0] == 1\n",
    "                \n",
    "                if is_kalimba:\n",
    "                    # Detekce tónu a aktualizace výpisu\n",
    "                    predicted_label, confidence = process_audio(segment)\n",
    "                    tone = label_to_tone[predicted_label]\n",
    "                    last_tone = f\"{tone} ({confidence*100:.1f}%)\"\n",
    "                    output = f\"Poslední detekce: {last_tone.ljust(20)} | Čas: {time.strftime('%H:%M:%S')}\\r\"\n",
    "                    print(output, end='')\n",
    "                    last_detection_time = current_time\n",
    "                else:\n",
    "                    # Krátkodobá informace o cizím zvuku bez přepsání detekce\n",
    "                    print(f\" [Cizí zvuk ignorován]\".ljust(30) + \"\\r\", end='')\n",
    "                    time.sleep(0.5)  # Krátká pauza pro čitelnost\n",
    "                    print(f\"Poslední detekce: {last_tone.ljust(20)} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d39b805d-ced3-4c72-a4e2-eba29036d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokračujeme dále 3.3.2025:1:51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95245b8f-55c4-4d6b-ba8d-68c462b73858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE KALIMBY A TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:35\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:35\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:36\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:36\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:37\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:37\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:38\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:39\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:39\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:40\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:40\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:41\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:41\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:42\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:42\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:43\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:43\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:44\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:44\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:45\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:45\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:46\n",
      "Poslední detekce: Nejedná se o kalimbu | Čas: 01:52:46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 69\u001b[0m\n\u001b[0;32m     65\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([buffer, audio_queue\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39msqueeze()])\n\u001b[0;32m     67\u001b[0m buffer \u001b[38;5;241m=\u001b[39m buffer[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(SAMPLE_RATE\u001b[38;5;241m*\u001b[39mBUFFER_DURATION):] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m>\u001b[39m SAMPLE_RATE\u001b[38;5;241m*\u001b[39mBUFFER_DURATION \u001b[38;5;28;01melse\u001b[39;00m buffer\n\u001b[1;32m---> 69\u001b[0m onsets \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_onset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(onsets) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (current_time \u001b[38;5;241m-\u001b[39m last_detection_time) \u001b[38;5;241m>\u001b[39m MIN_DELAY:\n",
      "Cell \u001b[1;32mIn[51], line 52\u001b[0m, in \u001b[0;36mdetect_onset\u001b[1;34m(buffer)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_onset\u001b[39m(buffer):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monset_detect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mONSET_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\onset.py:158\u001b[0m, in \u001b[0;36monset_detect\u001b[1;34m(y, sr, onset_envelope, hop_length, backtrack, energy, units, normalize, sparse, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my or onset_envelope must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m     onset_envelope \u001b[38;5;241m=\u001b[39m \u001b[43monset_strength\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Shift onset envelope up to be non-negative\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# (a common normalization step to make the threshold more consistent)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Normalize onset strength function to [0, 1] range\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Normalization is performed over the trailing axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\onset.py:351\u001b[0m, in \u001b[0;36monset_strength\u001b[1;34m(y, sr, S, lag, max_size, ref, detrend, center, feature, aggregate, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m    348\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate parameter cannot be False when computing full-spectrum onset strength.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m     )\n\u001b[1;32m--> 351\u001b[0m odf_all \u001b[38;5;241m=\u001b[39m \u001b[43monset_strength_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetrend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m odf_all[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\onset.py:581\u001b[0m, in \u001b[0;36monset_strength_multi\u001b[1;34m(y, sr, S, n_fft, hop_length, lag, max_size, ref, detrend, center, feature, aggregate, channels, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;66;03m# First, compute mel spectrogram\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     S \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mfeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# Convert to dBs\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     S \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mpower_to_db(S)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\feature\\spectral.py:2143\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2130\u001b[0m S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[0;32m   2131\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2132\u001b[0m     S\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2139\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2140\u001b[0m )\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m-> 2143\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m \u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...ft,mf->...mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, S, mel_basis, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\filters.py:231\u001b[0m, in \u001b[0;36mmel\u001b[1;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[0;32m    228\u001b[0m mel_f \u001b[38;5;241m=\u001b[39m mel_frequencies(n_mels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, fmin\u001b[38;5;241m=\u001b[39mfmin, fmax\u001b[38;5;241m=\u001b[39mfmax, htk\u001b[38;5;241m=\u001b[39mhtk)\n\u001b[0;32m    230\u001b[0m fdiff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiff(mel_f)\n\u001b[1;32m--> 231\u001b[0m ramps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msubtract\u001b[38;5;241m.\u001b[39mouter(mel_f, fftfreqs)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_mels):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# lower and upper slopes for all bins\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     lower \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mramps[i] \u001b[38;5;241m/\u001b[39m fdiff[i]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "import joblib\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "\n",
    "# Načtení modelů\n",
    "kalimba_model = joblib.load(\"kalimba_ocsvm.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "tone_model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "\n",
    "label_to_tone = {\n",
    "    0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\",\n",
    "    7: \"C5\", 8: \"D5\", 9: \"E5\", 10: \"F5\", 11: \"G5\", 12: \"A5\", 13: \"B5\",\n",
    "    14: \"C6\", 15: \"D6\", 16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def extract_features(audio_segment):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_segment, sr=SAMPLE_RATE, n_mfcc=20)\n",
    "    return np.mean(mfccs, axis=1)  # Průměr přes časovou osu\n",
    "\n",
    "def is_kalimba(buffer):\n",
    "    feature_vector = extract_features(buffer)\n",
    "    feature_scaled = scaler.transform([feature_vector])\n",
    "    prediction = kalimba_model.predict(feature_scaled)\n",
    "    return prediction[0] == 1  # 1 = kalimba, -1 = jiný zvuk\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = tone_model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE KALIMBY A TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\")\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                if is_kalimba(segment):\n",
    "                    predicted_label, confidence = process_audio(segment)\n",
    "                    tone = label_to_tone[predicted_label]\n",
    "                    output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                else:\n",
    "                    output = \"Nejedná se o kalimbu\".ljust(20)\n",
    "                \n",
    "                print(f\"Poslední detekce: {output} | Čas: {time.strftime('%H:%M:%S')}\")\n",
    "                last_detection_time = current_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51cf3026-2eba-4558-9a4a-b972c905daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE KALIMBY A TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 28 features, but StandardScaler is expecting 13 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(segment) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2048\u001b[39m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Detekce kalimby\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     features \u001b[38;5;241m=\u001b[39m extract_features_from_segment(segment)\n\u001b[1;32m---> 84\u001b[0m     features_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     is_kalimba \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(features_scaled)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_kalimba \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;66;03m# Klasifikace tónu\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 28 features, but StandardScaler is expecting 13 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5\n",
    "\n",
    "# Načtení modelů\n",
    "svm_model = joblib.load(\"kalimba_ocsvm.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "tone_model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = {\n",
    "    0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", \n",
    "    5: \"A4\", 6: \"B4\", 7: \"C5\", 8: \"D5\", 9: \"E5\", \n",
    "    10: \"F5\", 11: \"G5\", 12: \"A5\", 13: \"B5\", 14: \"C6\", \n",
    "    15: \"D6\", 16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def extract_features_from_segment(y):\n",
    "    # MFCC features (přizpůsobte původní implementaci)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=SAMPLE_RATE, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_std = np.std(mfccs, axis=1)\n",
    "    \n",
    "    # Další příznaky (přidejte vlastní podle tréninku modelu)\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=SAMPLE_RATE))\n",
    "    zero_crossing = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    \n",
    "    return np.concatenate([mfccs_mean, mfccs_std, [spectral_centroid, zero_crossing]])\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, \n",
    "                                            hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = tone_model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', \n",
    "        hop_length=512, delta=ONSET_THRESHOLD, \n",
    "        pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, \n",
    "                   samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE KALIMBY A TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                # Detekce kalimby\n",
    "                features = extract_features_from_segment(segment)\n",
    "                features_scaled = scaler.transform([features])\n",
    "                is_kalimba = svm_model.predict(features_scaled)[0]\n",
    "                \n",
    "                if is_kalimba == 1:\n",
    "                    # Klasifikace tónu\n",
    "                    label, confidence = process_audio(segment)\n",
    "                    tone = label_to_tone[label]\n",
    "                    output = f\"{tone} ({confidence*100:.1f}%)\".ljust(25)\n",
    "                    status = f\"Kalimba: {output}\"\n",
    "                else:\n",
    "                    status = \"Cizí zvuk - není kalimba\".ljust(40)\n",
    "                \n",
    "                print(f\"Poslední detekce: {status} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                last_detection_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38d7b906-8fe1-4514-b4f5-c769a31ced27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n",
      "Poslední detekce:                       Čekám na tón...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poslední detekce: F5 (100.0%)          | Čas: 02:25:00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SUPER FUNGUJE!!! NEJLEPŠÍ ZATÍM!\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "CONFIDENCE_THRESHOLD = 0.7  # Práh jistoty 70 %\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = {\n",
    "    0: \"C4\", \n",
    "    1: \"D4\", \n",
    "    2: \"E4\", \n",
    "    3: \"F4\", \n",
    "    4: \"G4\", \n",
    "    5: \"A4\", \n",
    "    6: \"B4\", \n",
    "    7: \"C5\", \n",
    "    8: \"D5\", \n",
    "    9: \"E5\", \n",
    "    10: \"F5\", \n",
    "    11: \"G5\", \n",
    "    12: \"A5\", \n",
    "    13: \"B5\", \n",
    "    14: \"C6\", \n",
    "    15: \"D6\", \n",
    "    16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:  # Podmínka pro jistotu nad 70 %\n",
    "                    tone = label_to_tone[predicted_label]\n",
    "                    output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                    print(f\"Poslední detekce: {output} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                    last_detection_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33f2fafb-ddab-40e6-a1e5-f1b597242193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tóny v pořadí: E5 C5 B4 C5 E5 C5 B4 C5 E5 C5 B4 C5 G5 G5 F5 F5 E5\n",
      "Celkem tónů: 17\n",
      "\n",
      "Poslední detekce: E5 (100.0%)          | Správně: 0/17 | Čas: 02:27:15\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "CONFIDENCE_THRESHOLD = 0.8  # Práh jistoty 70 %\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = {\n",
    "    0: \"C4\", \n",
    "    1: \"D4\", \n",
    "    2: \"E4\", \n",
    "    3: \"F4\", \n",
    "    4: \"G4\", \n",
    "    5: \"A4\", \n",
    "    6: \"B4\", \n",
    "    7: \"C5\", \n",
    "    8: \"D5\", \n",
    "    9: \"E5\", \n",
    "    10: \"F5\", \n",
    "    11: \"G5\", \n",
    "    12: \"A5\", \n",
    "    13: \"B5\", \n",
    "    14: \"C6\", \n",
    "    15: \"D6\", \n",
    "    16: \"E6\"\n",
    "}\n",
    "\n",
    "# Definice požadované sekvence tónů (podle indexů v label_to_tone)\n",
    "TARGET_SEQUENCE = [9, 7, 6, 7, 9, 7, 6, 7, 9, 7, 6, 7, 11, 11, 10, 10, 9]\n",
    "TOTAL_NOTES = len(TARGET_SEQUENCE)  # Celkový počet tónů v sekvenci (17)\n",
    "current_position = 0  # Aktuální pozice v sekvenci\n",
    "correct_notes = 0  # Počet správně zahraných tónů\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tóny v pořadí: E5 C5 B4 C5 E5 C5 B4 C5 E5 C5 B4 C5 G5 G5 F5 F5 E5\")\n",
    "    print(f\"Celkem tónů: {TOTAL_NOTES}\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:  # Podmínka pro jistotu nad 70 %\n",
    "                    tone = label_to_tone[predicted_label]\n",
    "                    # Kontrola, zda detekovaný tón odpovídá aktuálnímu v sekvenci\n",
    "                    if predicted_label == TARGET_SEQUENCE[current_position]:\n",
    "                        correct_notes += 1\n",
    "                        current_position += 1\n",
    "                    else:\n",
    "                        current_position = 0  # Reset pozice při chybě\n",
    "                        correct_notes = 0     # Reset správných tónů při chybě\n",
    "                    \n",
    "                    # Výpis výsledku\n",
    "                    output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                    progress = f\"Správně: {correct_notes}/{TOTAL_NOTES}\"\n",
    "                    print(f\"Poslední detekce: {output} | {progress} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                    last_detection_time = current_time\n",
    "                    \n",
    "                    # Pokud je sekvence dokončena\n",
    "                    if current_position == TOTAL_NOTES:\n",
    "                        print(f\"\\nGratuluji! Úspěšně jste zahráli celou sekvenci ({correct_notes}/{TOTAL_NOTES})!\")\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99fea6fc-6a4d-4947-892d-131bfed8ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tóny v pořadí: E5 C5 B4 C5 E5 C5 B4 C5 E5 C5 B4 C5 G5 G5 F5 F5 E5\n",
      "Celkem tónů: 17\n",
      "\n",
      "Poslední detekce: E6 (83.9%)           | Správně: 0/17 | Čas: 22:41:40"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     86\u001b[39m segment = buffer[start_sample:]\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(segment) > \u001b[32m2048\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     predicted_label, confidence = \u001b[43mprocess_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m confidence >= CONFIDENCE_THRESHOLD:  \u001b[38;5;66;03m# Podmínka pro jistotu nad 70 %\u001b[39;00m\n\u001b[32m     91\u001b[39m         tone = label_to_tone[predicted_label]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mprocess_audio\u001b[39m\u001b[34m(buffer)\u001b[39m\n\u001b[32m     53\u001b[39m mel_spec_db = tf.image.resize(mel_spec_db, (\u001b[32m128\u001b[39m, \u001b[32m128\u001b[39m)).numpy()\n\u001b[32m     54\u001b[39m input_data = np.expand_dims(mel_spec_db, axis=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m predictions = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.argmax(predictions[\u001b[32m0\u001b[39m]), np.max(predictions[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:557\u001b[39m, in \u001b[36mTensorFlowTrainer.predict\u001b[39m\u001b[34m(self, x, batch_size, verbose, steps, callbacks)\u001b[39m\n\u001b[32m    555\u001b[39m outputs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_predict_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:734\u001b[39m, in \u001b[36mTFEpochIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_epoch_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:112\u001b[39m, in \u001b[36mEpochIterator._enumerate_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m._current_iterator\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._steps_seen >= \u001b[38;5;28mself\u001b[39m._num_batches:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_iterator = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m._steps_seen = \u001b[32m0\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[39m, in \u001b[36mDatasetV2.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops.inside_function():\n\u001b[32m    500\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33miteration in eager mode or within tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:709\u001b[39m, in \u001b[36mOwnedIterator.__init__\u001b[39m\u001b[34m(self, dataset, components, element_spec)\u001b[39m\n\u001b[32m    705\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    707\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    708\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnot be specified.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[38;5;28mself\u001b[39m._get_next_call_count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:748\u001b[39m, in \u001b[36mOwnedIterator._create_iterator\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    745\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype.args[\u001b[32m0\u001b[39m].args[\u001b[32m0\u001b[39m].args) == \u001b[38;5;28mlen\u001b[39m(\n\u001b[32m    746\u001b[39m       \u001b[38;5;28mself\u001b[39m._flat_output_types)\n\u001b[32m    747\u001b[39m   \u001b[38;5;28mself\u001b[39m._iterator_resource.op.experimental_set_type(fulltype)\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3509\u001b[39m, in \u001b[36mmake_iterator\u001b[39m\u001b[34m(dataset, iterator, name)\u001b[39m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   3508\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3509\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3510\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMakeIterator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3512\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 2.0  # Minimální prodleva mezi detekcemi (zvýšeno na 1 sekundu)\n",
    "CONFIDENCE_THRESHOLD = 0.8  # Práh jistoty 70 %\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = {\n",
    "    0: \"C4\", \n",
    "    1: \"D4\", \n",
    "    2: \"E4\", \n",
    "    3: \"F4\", \n",
    "    4: \"G4\", \n",
    "    5: \"A4\", \n",
    "    6: \"B4\", \n",
    "    7: \"C5\", \n",
    "    8: \"D5\", \n",
    "    9: \"E5\", \n",
    "    10: \"F5\", \n",
    "    11: \"G5\", \n",
    "    12: \"A5\", \n",
    "    13: \"B5\", \n",
    "    14: \"C6\", \n",
    "    15: \"D6\", \n",
    "    16: \"E6\"\n",
    "}\n",
    "\n",
    "# Definice požadované sekvence tónů (podle indexů v label_to_tone)\n",
    "TARGET_SEQUENCE = [9, 7, 6, 7, 9, 7, 6, 7, 9, 7, 6, 7, 11, 11, 10, 10, 9]\n",
    "TOTAL_NOTES = len(TARGET_SEQUENCE)  # Celkový počet tónů v sekvenci (17)\n",
    "current_position = 0  # Aktuální pozice v sekvenci\n",
    "correct_notes = 0  # Počet správně zahraných tónů\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tóny v pořadí: E5 C5 B4 C5 E5 C5 B4 C5 E5 C5 B4 C5 G5 G5 F5 F5 E5\")\n",
    "    print(f\"Celkem tónů: {TOTAL_NOTES}\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:  # Podmínka pro jistotu nad 70 %\n",
    "                    tone = label_to_tone[predicted_label]\n",
    "                    # Kontrola, zda detekovaný tón odpovídá aktuálnímu v sekvenci\n",
    "                    if predicted_label == TARGET_SEQUENCE[current_position]:\n",
    "                        correct_notes += 1\n",
    "                        current_position += 1\n",
    "                    else:\n",
    "                        current_position = 0  # Reset pozice při chybě\n",
    "                        correct_notes = 0     # Reset správných tónů při chybě\n",
    "                    \n",
    "                    # Výpis výsledku\n",
    "                    output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                    progress = f\"Správně: {correct_notes}/{TOTAL_NOTES}\"\n",
    "                    print(f\"Poslední detekce: {output} | {progress} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                    last_detection_time = current_time\n",
    "                    \n",
    "                    # Pokud je sekvence dokončena\n",
    "                    if current_position == TOTAL_NOTES:\n",
    "                        print(f\"\\nGratuluji! Úspěšně jste zahráli celou sekvenci ({correct_notes}/{TOTAL_NOTES})!\")\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d6fc5-efbd-446f-b8bb-fb99ed5b2bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]\n",
      "2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALTIME DETEKCE TÓNŮ ===\n",
      "Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\n",
      "\n",
      "Poslední detekce:                       Čekám na tón...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poslední detekce: A4 (91.5%)           | Čas: 00:59:08\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "print(np.__version__)\n",
    "\n",
    "# Nastavení parametrů\n",
    "SAMPLE_RATE = 22050\n",
    "BUFFER_DURATION = 1.0\n",
    "ONSET_THRESHOLD = 0.3\n",
    "MIN_DELAY = 0.5  # Minimální prodleva mezi detekcemi (v sekundách)\n",
    "CONFIDENCE_THRESHOLD = 0.7  # Minimální požadovaná jistota detekce\n",
    "\n",
    "# Načtení modelu\n",
    "model = tf.keras.models.load_model(\"tone_recognition_multi_label.h5\")\n",
    "\n",
    "audio_queue = Queue()\n",
    "last_detection_time = 0\n",
    "label_to_tone = {\n",
    "    0: \"C4\", 1: \"D4\", 2: \"E4\", 3: \"F4\", 4: \"G4\", 5: \"A4\", 6: \"B4\", \n",
    "    7: \"C5\", 8: \"D5\", 9: \"E5\", 10: \"F5\", 11: \"G5\", 12: \"A5\", 13: \"B5\", \n",
    "    14: \"C6\", 15: \"D6\", 16: \"E6\"\n",
    "}\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def process_audio(buffer):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=buffer, sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)\n",
    "    mel_spec_db = tf.image.resize(mel_spec_db, (128, 128)).numpy()\n",
    "    input_data = np.expand_dims(mel_spec_db, axis=0)\n",
    "    predictions = model.predict(input_data, verbose=0)\n",
    "    return np.argmax(predictions[0]), np.max(predictions[0])\n",
    "\n",
    "def detect_onset(buffer):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=buffer, sr=SAMPLE_RATE, units='samples', hop_length=512,\n",
    "        delta=ONSET_THRESHOLD, pre_max=3, post_max=3\n",
    "    )\n",
    "\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE, blocksize=int(SAMPLE_RATE*0.1)):\n",
    "    print(\"=== REALTIME DETEKCE TÓNŮ ===\")\n",
    "    print(\"Hrajte tón na mikrofon... (Ctrl+C pro ukončení)\\n\")\n",
    "    print(\"Poslední detekce:\".ljust(40) + \"Čekám na tón...\\r\", end='')\n",
    "    \n",
    "    buffer = np.array([], dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        # Aktualizace bufferu\n",
    "        while not audio_queue.empty():\n",
    "            buffer = np.concatenate([buffer, audio_queue.get().squeeze()])\n",
    "        \n",
    "        # Omezíme délku bufferu\n",
    "        buffer = buffer[-int(SAMPLE_RATE*BUFFER_DURATION):] if len(buffer) > SAMPLE_RATE*BUFFER_DURATION else buffer\n",
    "        \n",
    "        # Detekce onsetů\n",
    "        onsets = detect_onset(buffer)\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if len(onsets) > 0 and (current_time - last_detection_time) > MIN_DELAY:\n",
    "            start_sample = onsets[-1]\n",
    "            segment = buffer[start_sample:]\n",
    "            \n",
    "            if len(segment) > 2048:\n",
    "                predicted_label, confidence = process_audio(segment)\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    tone = label_to_tone[predicted_label]\n",
    "                    output = f\"{tone} ({confidence*100:.1f}%)\".ljust(20)\n",
    "                    print(f\"Poslední detekce: {output} | Čas: {time.strftime('%H:%M:%S')}\\r\", end='')\n",
    "                    last_detection_time = current_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be0276-c98e-44e6-8c59-bb8d08a6a371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
